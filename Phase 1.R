# ============================================================
# Phase 1: Data Understanding & Cleaning (R)
# Dataset: Credit Card Fraud Detection (Kaggle - ULB)
# ============================================================

# â”€â”€ 1. Install & Load Libraries â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
install.packages(c("tidyverse", "skimr", "janitor"))

library(tidyverse)   # Data manipulation
library(skimr)       # Summary statistics
library(janitor)     # Cleaning helpers

# â”€â”€ 2. Load Dataset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
setwd("C:/Users/SRI/OneDrive/Desktop/Desktop/Intro to DS")
df <- read.csv("creditcard.csv")

cat("âœ… Dataset Loaded\n")
cat("Rows:", nrow(df), "| Columns:", ncol(df), "\n")

# â”€â”€ 3. Initial Exploration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
head(df, 5)          # First 5 rows
str(df)              # Data types
dim(df)              # Dimensions

# â”€â”€ 4. Summary Statistics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
summary(df)
skim(df)             # Detailed stats: mean, sd, missing, histograms

# â”€â”€ 5. Check for Missing Values â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
missing_vals <- colSums(is.na(df))
cat("\nðŸ” Missing Values per Column:\n")
print(missing_vals[missing_vals > 0])  # Show only columns with missing data

# If missing values exist, impute with median (safe for skewed data)
df <- df %>%
  mutate(across(where(is.numeric), ~ ifelse(is.na(.), median(., na.rm = TRUE), .)))

cat("âœ… Missing values handled\n")

# â”€â”€ 6. Remove Duplicates â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
before <- nrow(df)
df <- df %>% distinct()
after  <- nrow(df)

cat("ðŸ—‘ï¸ Duplicates removed:", before - after, "\n")
cat("Remaining rows:", after, "\n")

# â”€â”€ 7. Check Class Distribution (Fraud vs Normal) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class_dist <- df %>%
  count(Class) %>%
  mutate(
    Label      = ifelse(Class == 0, "Normal", "Fraud"),
    Percentage = round(n / sum(n) * 100, 2)
  )

print(class_dist)

# â”€â”€ 8. Outlier Check on 'Amount' â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cat("\nðŸ’° Amount column stats:\n")
cat("Min:", min(df$Amount), "\n")
cat("Max:", max(df$Amount), "\n")
cat("Mean:", mean(df$Amount), "\n")
cat("Median:", median(df$Amount), "\n")

# Box plot to visualise outliers
boxplot(df$Amount,
        main = "Boxplot of Transaction Amount",
        ylab = "Amount (USD)",
        col  = "steelblue",
        outline = TRUE)

# â”€â”€ 9. Normalise 'Amount' and 'Time' columns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# These are raw; all V1â€“V28 are already PCA-scaled
df$Amount_scaled <- scale(df$Amount)
df$Time_scaled   <- scale(df$Time)

# Drop original raw columns (optional â€” keep if needed for Tableau)
df_model <- df %>% select(-Amount, -Time)

cat("âœ… Amount and Time columns normalised\n")

# â”€â”€ 10. Sampling â€” Train/Validation Split â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
set.seed(42)  # For reproducibility

sample_index <- sample(1:nrow(df_model), size = 0.8 * nrow(df_model))
train_data   <- df_model[sample_index, ]
valid_data   <- df_model[-sample_index, ]

cat("ðŸ“Š Training set size:", nrow(train_data), "\n")
cat("ðŸ“Š Validation set size:", nrow(valid_data), "\n")

# â”€â”€ 11. Save Cleaned Dataset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
write.csv(df_model,   "creditcard_cleaned.csv",    row.names = FALSE)
write.csv(train_data, "creditcard_train.csv",      row.names = FALSE)
write.csv(valid_data, "creditcard_validation.csv", row.names = FALSE)

cat("âœ… Cleaned files saved: creditcard_cleaned.csv, _train.csv, _validation.csv\n")